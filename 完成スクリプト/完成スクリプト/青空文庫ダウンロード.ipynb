{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 青空文庫データのスクレイピングとクリーニング\n",
    "このスクリプトは青空文庫から指定された作品をダウンロードし、HTMLタグを除去してルビや不要な文字をクリーンアップし、\n",
    "指定したディレクトリにクリーンなテキストを保存します。\n",
    "\n",
    "### 使用方法\n",
    "1. 必要なライブラリをインストールします。\n",
    "2. `url` 変数に青空文庫の作品ページのURLを設定します。ダウンロードしたい作品のhtmlを開き、URLをコピーしてください。\n",
    "3. `output_directory` と `filename` を設定して、保存先のディレクトリとファイル名を指定します。\n",
    "4. スクリプトを実行すると、指定したURLからデータを取得し、テキストクリーニングを行った後、ファイルに保存します。\n",
    "\n",
    "### 参考\n",
    "[文章生成] スクレイピングで青空文庫からデータを取得してみよう：作って試そう！ ディープラーニング工作室\n",
    "https://atmarkit.itmedia.co.jp/ait/articles/2101/29/news030.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install beautifulsoup4 lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 青空文庫から特定の作品のURLを指定\n",
    "url = 'https://www.aozora.gr.jp/cards/000148/files/773_14560.html'\n",
    "\n",
    "# 保存したいディレクトリとファイル名を指定\n",
    "output_directory = 'ディレクトリ名'\n",
    "filename = 'cleaned_text.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib import request\n",
    "import re\n",
    "import os\n",
    "\n",
    "response = request.urlopen(url)\n",
    "soup = BeautifulSoup(response, 'html.parser')\n",
    "response.close()\n",
    "\n",
    "# divタグでclass=\"main_text\"を検索し、その中の本文だけを取得\n",
    "main_text = soup.find('div', class_='main_text')\n",
    "\n",
    "# <rp>タグと<rt>タグを削除\n",
    "tags_to_delete = main_text.find_all(['rp', 'rt'])\n",
    "for tag in tags_to_delete:\n",
    "    tag.decompose()\n",
    "\n",
    "# タグを削除した後のテキストからさらにルビ情報を削除\n",
    "main_text = main_text.get_text()\n",
    "main_text = re.sub('（[\\u3041-\\u309F]+）', '', main_text)\n",
    "\n",
    "# 不要な文字を削除\n",
    "main_text = main_text.replace('\\r', '').replace('\\n', '').replace('\\u3000', '')\n",
    "\n",
    "# 結果を表示\n",
    "print(main_text)\n",
    "\n",
    "# ディレクトリが存在しない場合は作成\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# 完全なファイルパスを生成\n",
    "file_path = os.path.join(output_directory, filename)\n",
    "\n",
    "# ファイルにテキストを書き込む\n",
    "with open(file_path, 'w', encoding='utf-8') as file:\n",
    "    file.write(main_text)\n",
    "\n",
    "print(f'ファイルが保存されました: {file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib import request\n",
    "import re\n",
    "import os\n",
    "\n",
    "# SSL証明書の検証を無効にするコンテキストを作成\n",
    "context = ssl._create_unverified_context()\n",
    "\n",
    "url = 'https://www.aozora.gr.jp/cards/000074/files/427_19793.html'\n",
    "response = request.urlopen(url, context=context)\n",
    "soup = BeautifulSoup(response, 'html.parser')\n",
    "response.close()\n",
    "\n",
    "# divタグでclass=\"main_text\"を検索し、その中の本文だけを取得\n",
    "main_text = soup.find('div', class_='main_text')\n",
    "\n",
    "# <rp>タグと<rt>タグを削除\n",
    "tags_to_delete = main_text.find_all(['rp', 'rt'])\n",
    "for tag in tags_to_delete:\n",
    "    tag.decompose()\n",
    "\n",
    "# タグを削除した後のテキストからさらにルビ情報を削除\n",
    "main_text = main_text.get_text()\n",
    "main_text = re.sub('（[\\u3041-\\u309F]+）', '', main_text)\n",
    "\n",
    "# 不要な文字を削除\n",
    "main_text = main_text.replace('\\r', '').replace('\\n', '').replace('\\u3000', '')\n",
    "\n",
    "# 結果を表示\n",
    "print(main_text)\n",
    "\n",
    "# ディレクトリが存在しない場合は作成\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# 完全なファイルパスを生成\n",
    "file_path = os.path.join(output_directory, filename)\n",
    "\n",
    "# ファイルにテキストを書き込む\n",
    "with open(file_path, 'w', encoding='utf-8') as file:\n",
    "    file.write(main_text)\n",
    "\n",
    "print(f'ファイルが保存されました: {file_path}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
